{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "most confusing words.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOW2m9uf5ffK4QookfkM4zi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dween46/Web-Scraping-from-vocabulary-website-/blob/main/most_confusing_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Commonly Confused Words\n",
        "\n",
        "In this project we will scrape most confusing words from vocabulary.com website. \n",
        "\n",
        "Here is the link of the webpage: https://www.vocabulary.com/articles/chooseyourwords/\n",
        "\n",
        "\n",
        "We find these words in different language tests like IELTS, GRE , TOEFL etc. As this is a hassle to read those words from web page, we want to make a pdf of those words so that learnig these words get easier. \n",
        "\n",
        "If we go thrugh the website every word pair has continue reading hyperlink page which contains full details of the word pair like definition and example sentences. \n",
        "\n",
        "we want to extract that information for each word pair. There is 180 word pairs. After extracting the word pairs we will make a PDF file. "
      ],
      "metadata": {
        "id": "fOrP-gxJacR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Necessary  imports we need to complete this project.\n",
        "For now on, we will use BeautifulSoup and requests python package. Let's import those."
      ],
      "metadata": {
        "id": "uMOvH5fFcPt0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "XotXpUUNHm_N"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_url = \"https://www.vocabulary.com\"\n",
        "url  = \"https://www.vocabulary.com/articles/chooseyourwords/\""
      ],
      "metadata": {
        "id": "ZtpdE01eI2KL"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will create a fucntion to parse all the word pair link. "
      ],
      "metadata": {
        "id": "0_3eEdl4c9Ed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_links(url):\n",
        "  \"\"\"function to get the word links\n",
        "  \"\"\"\n",
        "  response = requests.get(url).text\n",
        "  soup = BeautifulSoup(response)\n",
        "  all_words = soup.find_all(\"a\", {\"class\": \"readMore\"})\n",
        "\n",
        "  links = []\n",
        "  for word in all_words:\n",
        "    links.append(main_url+word['href'])\n",
        "  \n",
        "  return links"
      ],
      "metadata": {
        "id": "TWyM_-qvJoX8"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_urls = parse_links(url)\n",
        "len(word_urls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg7KWipYPtXu",
        "outputId": "4f03a70f-830e-4db2-ee52-0f0049285378"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we found 180 word pair links. Now we have to parse the whole text for each word pair. "
      ],
      "metadata": {
        "id": "F5a2Q-4VdHU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_text(url):\n",
        "  \"\"\"function to find all the texts from the given link\n",
        "  \"\"\"\n",
        "  #getting the html response\n",
        "  response = requests.get(url).text\n",
        "  soup = BeautifulSoup(response)\n",
        "\n",
        "  all_paragraphs = soup.find_all(\"p\")\n",
        "  all_paragraphs.pop() #deleting the last element as this is not needed\n",
        "\n",
        "  title = soup.find_all(\"span\", {\"class\": \"level\"})[0].text\n",
        "\n",
        "  #assimilating all of the texts in single string\n",
        "  whole_text = title\n",
        "  for p in all_paragraphs:\n",
        "    whole_text += \"\\n\\n\"\n",
        "    whole_text += p.text \n",
        "\n",
        "  return whole_text"
      ],
      "metadata": {
        "id": "6l_oRX1WSSIu"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We created the function. now we have to save the text of all word pairs in a text file. "
      ],
      "metadata": {
        "id": "lvitNWWjdVKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for u in word_urls:\n",
        "  line = parse_text(u)\n",
        "  with open('whole_task.txt', 'a') as f:\n",
        "    f.write(line)\n",
        "    f.write('\\n\\n\\n\\n')\n"
      ],
      "metadata": {
        "id": "p2zJMmp1UWCs"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So our task is complete. Output is saved in whole_task.txt file. Now we need to convert this into a docx file using MS word. After that we will edit the file to decorate the text for better reading view and to create the expected PDF. \n",
        "\n",
        "Complete yeeyyyy! "
      ],
      "metadata": {
        "id": "DslC5teTgMvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8azmA20rg3_S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}